import os
import streamlit as st
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain_openai import ChatOpenAI

# ‚úÖ Load secrets from Streamlit Cloud or hardcoded for local dev
os.environ["OPENAI_API_KEY"] = "sk-aa47d49919ad4a8795605774abad2b49"
os.environ["OPENAI_API_BASE"] = "https://api.deepseek.com/v1"

# ‚úÖ Path to vector DB
persist_directory = "./chroma_db_combined"

# ‚úÖ Streamlit UI setup
st.set_page_config(page_title="Treasury AI Assistant", layout="wide")
st.markdown("""
<style>
.block-container { padding-top: 2rem; }
.stTextInput > div > div > input { font-size: 1.1rem; }
.stMarkdown h1, h2, h3 { margin-top: 1.5rem; }
</style>
""", unsafe_allow_html=True)

st.title("üìÑ Treasury AI Assistant")
st.caption("Ask questions about HKJC‚≠ê.")

# Initialize chat history
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

def main():
    try:
        # ‚úÖ Load vector DB and retriever
        embedding = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)
        retriever = vectordb.as_retriever()

        # ‚úÖ Load LLM from DeepSeek
        llm = ChatOpenAI(
            model_name="deepseek-chat",
            temperature=0.3,
            openai_api_key=os.environ["OPENAI_API_KEY"],
            openai_api_base=os.environ["OPENAI_API_BASE"]
        )

        # ‚úÖ Setup ConversationalRetrievalChain
        rag_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=retriever,
            return_source_documents=True
        )

        # ‚úÖ User input
        query = st.text_input("üí¨ Ask something about your documents...", placeholder="e.g. What is the conclusion?")
        if query:
            with st.spinner("ü§ñ Thinking..."):
                result = rag_chain({
                    "question": query,
                    "chat_history": st.session_state.chat_history
                })

            # ‚úÖ Update chat history
            st.session_state.chat_history.append((query, result["answer"]))

            # ‚úÖ Show answer
            st.markdown("### üß† Answer")
            st.success(result["answer"])

            # ‚úÖ Show sources
            with st.expander("üìÑ Source Documents"):
                for i, doc in enumerate(result["source_documents"]):
                    st.markdown(f"**Source {i+1}:**")
                    st.code(doc.page_content[:1000], language="markdown")

    except Exception as e:
        st.error("‚ö†Ô∏è Something went wrong.")
        st.exception(e)

if __name__ == "__main__":
    main()